{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40be2fdb-db85-40f8-8c7d-91ae338b30fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fb6adf-f47a-4411-a363-dacd6cb629eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_building_polygons(json_folder):\n",
    "    rows = []\n",
    "\n",
    "    for filename in os.listdir(json_folder):\n",
    "        if filename.endswith(\".json\"):\n",
    "            json_path = os.path.join(json_folder, filename)\n",
    "            with open(json_path, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            img_name = filename.replace(\".json\", \".tif\")\n",
    "            features = data[\"features\"][\"xy\"]\n",
    "            metadata = data.get(\"metadata\", {})\n",
    "\n",
    "            parts = img_name.replace(\".tif\",\"\").split(\"_\")\n",
    "            stage = parts[2]\n",
    "            disaster_type = metadata.get(\"disaster_type\", None)\n",
    "\n",
    "            for feat in features:\n",
    "                props = feat[\"properties\"]\n",
    "                subtype = props.get(\"subtype\")\n",
    "                uid = props.get(\"uid\")\n",
    "                wkt = feat.get(\"wkt\")\n",
    "                disaster = disaster_type\n",
    "\n",
    "                rows.append({\n",
    "                    \"uid\": uid,\n",
    "                    \"image_id\": img_name,\n",
    "                    \"stage\": stage,\n",
    "                    \"subtype\": subtype,\n",
    "                    \"wkt\": wkt,\n",
    "                    \"disaster\": disaster\n",
    "                })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d739727-b2a1-4dad-b767-eb16ef07ca45",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m json_folder = \u001b[33m\"\u001b[39m\u001b[33m./tier1/labels\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      2\u001b[39m output_csv = \u001b[33m\"\u001b[39m\u001b[33mbuilding_polygons_metadata.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m df = extract_building_polygons(json_folder)\n\u001b[32m      5\u001b[39m df.to_csv(output_csv, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mextract_building_polygons\u001b[39m\u001b[34m(json_folder)\u001b[39m\n\u001b[32m      6\u001b[39m json_path = os.path.join(json_folder, filename)\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(json_path, \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     data = json.load(f)\n\u001b[32m     10\u001b[39m img_name = filename.replace(\u001b[33m\"\u001b[39m\u001b[33m.json\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m.tif\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m features = data[\u001b[33m\"\u001b[39m\u001b[33mfeatures\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mxy\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ext3/miniconda3/lib/python3.12/json/__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mload\u001b[39m(fp, *, \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28;01mNone\u001b[39;00m, object_hook=\u001b[38;5;28;01mNone\u001b[39;00m, parse_float=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    275\u001b[39m         parse_int=\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant=\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook=\u001b[38;5;28;01mNone\u001b[39;00m, **kw):\n\u001b[32m    276\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loads(fp.read(),\n\u001b[32m    294\u001b[39m         \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m         parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m         parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ext3/miniconda3/lib/python3.12/codecs.py:319\u001b[39m, in \u001b[36mBufferedIncrementalDecoder.decode\u001b[39m\u001b[34m(self, input, final)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m_buffer_decode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, errors, final):\n\u001b[32m    315\u001b[39m     \u001b[38;5;66;03m# Overwrite this method in subclasses: It must decode input\u001b[39;00m\n\u001b[32m    316\u001b[39m     \u001b[38;5;66;03m# and return an (output, length consumed) tuple\u001b[39;00m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    320\u001b[39m     \u001b[38;5;66;03m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[32m    321\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.buffer + \u001b[38;5;28minput\u001b[39m\n\u001b[32m    322\u001b[39m     (result, consumed) = \u001b[38;5;28mself\u001b[39m._buffer_decode(data, \u001b[38;5;28mself\u001b[39m.errors, final)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "json_folder = \"./tier1/labels\"\n",
    "output_csv = \"building_polygons_metadata.csv\"\n",
    "df = extract_building_polygons(json_folder)\n",
    "\n",
    "df.to_csv(output_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0186646-f34e-4d05-8305-9d421f75e4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    uid  \\\n",
      "0  8c42624a-d093-486c-ad1c-4fbd070faf6c   \n",
      "1  986e8b4d-c2ca-4fe3-946a-3757c1fa4435   \n",
      "2  a4069f10-166f-4b97-a25c-5af342975d42   \n",
      "3  ba868904-2116-49d5-a44c-a19dcb2a6361   \n",
      "4  42b9b7a8-ebce-405a-a888-1c4f4bf9300f   \n",
      "\n",
      "                                        image_id subtype  \\\n",
      "0  santa-rosa-wildfire_00000138_pre_disaster.tif     NaN   \n",
      "1  santa-rosa-wildfire_00000138_pre_disaster.tif     NaN   \n",
      "2  santa-rosa-wildfire_00000138_pre_disaster.tif     NaN   \n",
      "3  santa-rosa-wildfire_00000138_pre_disaster.tif     NaN   \n",
      "4  santa-rosa-wildfire_00000138_pre_disaster.tif     NaN   \n",
      "\n",
      "                                                 wkt disaster  \n",
      "0  POLYGON ((0 12.47651487918631, 14.511311627017...     fire  \n",
      "1  POLYGON ((2.881611831691816 49.11659135604885,...     fire  \n",
      "2  POLYGON ((55.88447421102212 0.4888322292836593...     fire  \n",
      "3  POLYGON ((78.42987464102379 22.27268595973858,...     fire  \n",
      "4  POLYGON ((54.64130596559908 127.5597927785371,...     fire  \n",
      "subtype\n",
      "no-damage        117426\n",
      "minor-damage      14980\n",
      "major-damage      14161\n",
      "destroyed         13227\n",
      "un-classified      2993\n",
      "Name: count, dtype: int64\n",
      "disaster\n",
      "flooding      76432\n",
      "wind          73250\n",
      "earthquake    64542\n",
      "tsunami       62788\n",
      "fire          46850\n",
      "volcano        1712\n",
      "Name: count, dtype: int64\n",
      "uid              0\n",
      "image_id         0\n",
      "subtype     162787\n",
      "wkt              0\n",
      "disaster         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(output_csv)\n",
    "\n",
    "print(df.head())\n",
    "print(df[\"subtype\"].value_counts())\n",
    "print(df[\"disaster\"].value_counts())\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c25dfd9a-0552-4888-a4e8-9c891d255daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rasterio\n",
      "  Using cached rasterio-1.4.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting affine (from rasterio)\n",
      "  Using cached affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs in /ext3/miniconda3/lib/python3.12/site-packages (from rasterio) (25.3.0)\n",
      "Requirement already satisfied: certifi in /ext3/miniconda3/lib/python3.12/site-packages (from rasterio) (2025.1.31)\n",
      "Collecting click>=4.0 (from rasterio)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting cligj>=0.5 (from rasterio)\n",
      "  Using cached cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: numpy>=1.24 in /ext3/miniconda3/lib/python3.12/site-packages (from rasterio) (2.1.3)\n",
      "Collecting click-plugins (from rasterio)\n",
      "  Using cached click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: pyparsing in /ext3/miniconda3/lib/python3.12/site-packages (from rasterio) (3.2.3)\n",
      "Using cached rasterio-1.4.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.3 MB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Using cached cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
      "Using cached affine-2.4.0-py3-none-any.whl (15 kB)\n",
      "Using cached click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
      "Installing collected packages: click, affine, cligj, click-plugins, rasterio\n",
      "Successfully installed affine-2.4.0 click-8.1.8 click-plugins-1.1.1 cligj-0.7.2 rasterio-1.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b975083-c305-40e8-b779-ce9344188c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "from shapely import wkt\n",
    "from PIL import Image\n",
    "from rasterio.windows import Window\n",
    "from shapely.geometry import Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a209a080-c904-424a-bd57-f77ff3fdb3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_building_to_square(image_path, wkt_str, crop_size=256):\n",
    "    \"\"\"\n",
    "    Crop the building polygon from the image and resize to square.\n",
    "    \n",
    "    - image_path (str): Path to the image file\n",
    "    - wkt_str (str): Well-Known Text (WKT) string for the building polygon\n",
    "    - crop_size (int): The size of the square crop\n",
    "    \n",
    "    Returns:\n",
    "    - PIL Image: The cropped and resized image\n",
    "    \"\"\"\n",
    "    \n",
    "    with rasterio.open(image_path) as src:\n",
    "        polygon = wkt.loads(wkt_str)\n",
    "        minx, miny, maxx, maxy = polygon.bounds\n",
    "        \n",
    "        # Calculate the center and dimensions of the bounding box\n",
    "        width = maxx - minx\n",
    "        height = maxy - miny\n",
    "        center_x = int((minx + maxx) / 2)\n",
    "        center_y = int((miny + maxy) / 2)\n",
    "        \n",
    "        # Resize the shorter side to match the longer side\n",
    "        if width > height:\n",
    "            new_height = width  # Match height to width\n",
    "            half_crop = new_height // 2\n",
    "            window = Window(\n",
    "                max(center_x - half_crop, 0),  # Prevent negative coordinates\n",
    "                max(center_y - new_height // 2, 0),\n",
    "                width,\n",
    "                new_height\n",
    "            )\n",
    "        else:\n",
    "            new_width = height  # Match width to height\n",
    "            half_crop = new_width // 2\n",
    "            window = Window(\n",
    "                max(center_x - new_width // 2, 0),\n",
    "                max(center_y - half_crop, 0),  # Prevent negative coordinates\n",
    "                new_width,\n",
    "                height\n",
    "            )\n",
    "        \n",
    "        # Read the window from the image\n",
    "        crop = src.read(window=window)\n",
    "        \n",
    "        # Convert from int16 to uint8\n",
    "        # First normalize to 0-1 range\n",
    "        crop = crop.astype(np.float32)\n",
    "        crop = (crop - crop.min()) / (crop.max() - crop.min())\n",
    "        # Then scale to 0-255 and convert to uint8\n",
    "        crop = (crop * 255).astype(np.uint8)\n",
    "        \n",
    "        # Convert to PIL Image for resizing\n",
    "        crop_image = Image.fromarray(crop.transpose(1, 2, 0))  # Convert from CHW to HWC format\n",
    "        \n",
    "        # Resize directly to target size\n",
    "        final_image = crop_image.resize((crop_size, crop_size), Image.Resampling.LANCZOS)\n",
    "        \n",
    "        return final_image \n",
    "    \n",
    "def crop_and_save_buildings(csv_path, image_dir, output_dir, crop_size=256, output_format=\"png\"):\n",
    "    \"\"\"\n",
    "    Process the CSV with building metadata, crop buildings from the image, \n",
    "    and save them as images in the specified format.\n",
    "    - csv_path (str): Path to the CSV file containing building metadata.\n",
    "    - image_dir (str): Directory where the original images (.tif) are stored.\n",
    "    - output_dir (str): Directory where cropped images will be saved.\n",
    "    - crop_size (int): Desired size of the square crop (default: 256).\n",
    "    - output_format (str): The format to save the cropped images (\"png\" by default).\n",
    "    \"\"\"\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Loop through the rows of the dataframe\n",
    "    for idx, row in df.iterrows():\n",
    "        uid = row['uid']\n",
    "        image_id = row['image_id']\n",
    "        stage = row['stage']\n",
    "        wkt_str = row['wkt']\n",
    "        disaster_type = row['disaster']\n",
    "        \n",
    "        # Skip rows where there is no valid WKT string or missing disaster type\n",
    "        if pd.isna(wkt_str) or pd.isna(disaster_type):\n",
    "            continue\n",
    "\n",
    "        pathe = os.path.join(output_dir, f\"{uid}_{stage}.{output_format}\")\n",
    "        if os.path.exists(pathe):\n",
    "            continue\n",
    "        \n",
    "        # Construct the image path based on the image_id (replace .json with .tif)\n",
    "        image_path = os.path.join(image_dir, image_id.replace('.json', '.tif'))\n",
    "        \n",
    "        # Perform the cropping\n",
    "        final_image = crop_building_to_square(image_path, wkt_str, crop_size)\n",
    "        \n",
    "        # Save the cropped image with a unique name (uid + output format)\n",
    "        output_image_path = os.path.join(output_dir, f\"{uid}_{stage}.{output_format}\")\n",
    "        \n",
    "        # Save the image in the specified output format\n",
    "        final_image.save(output_image_path, format=output_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93bf62e-35be-43a0-bd71-9fe3abc25b0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crop_and_save_buildings(\n",
    "    csv_path=\"building_polygons_metadata.csv\",\n",
    "    image_dir=\"./tier1/images\",\n",
    "    output_dir=\"./tier1/cropped_square_buildings\",\n",
    "    crop_size=256,\n",
    "    output_format=\"png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ff441b-28e4-4806-a4d7-683db1001df3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Custom Env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
