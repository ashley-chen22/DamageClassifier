{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tifffile as tiff\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "m8WbYkT6ghgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pPS-bXfd7Aw"
      },
      "outputs": [],
      "source": [
        "class DisasterDataset(Dataset):\n",
        "    def __init__(self, dataframe, image_dir, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        # Filter for post-disaster images with major damage or destroyed\n",
        "        filtered_df = dataframe[\n",
        "            (dataframe[\"stage\"] == \"post\") &\n",
        "            (dataframe[\"feature_type\"] == \"building\") &\n",
        "            (dataframe[\"subtype\"].isin([\"major-damage\", \"destroyed\"]))\n",
        "        ]\n",
        "\n",
        "        # Map disaster types to labels\n",
        "        disaster_labels = {\n",
        "            'volcano': 1,\n",
        "            'fire': 2,\n",
        "            'tsunami': 3,\n",
        "            'flooding': 4,\n",
        "            'earthquake': 5,\n",
        "            'wind': 6,\n",
        "            'hurricane': 7\n",
        "        }\n",
        "\n",
        "\n",
        "        self.pairs = {}\n",
        "        for _, row in filtered_df.iterrows():\n",
        "            filename = row[\"image_filename\"]\n",
        "            prefix = \"_\".join(filename.split(\"_\")[:2])\n",
        "            stage = row[\"stage\"]\n",
        "            disaster_type = row[\"disaster_type\"]\n",
        "\n",
        "            if prefix not in self.pairs:\n",
        "                self.pairs[prefix] = {\"label\": disaster_labels[disaster_type]}\n",
        "\n",
        "            self.pairs[prefix][stage] = filename\n",
        "\n",
        "\n",
        "        self.pairs = [v for v in self.pairs.values() if \"pre\" in v and \"post\" in v]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.pairs[idx]\n",
        "        pre_path = os.path.join(self.image_dir, item[\"pre\"])\n",
        "        post_path = os.path.join(self.image_dir, item[\"post\"])\n",
        "\n",
        "        pre_img = tiff.imread(pre_path)\n",
        "        post_img = tiff.imread(post_path)\n",
        "\n",
        "        pre_img = np.expand_dims(pre_img, axis=-1) if pre_img.ndim == 2 else pre_img\n",
        "        post_img = np.expand_dims(post_img, axis=-1) if post_img.ndim == 2 else post_img\n",
        "\n",
        "        pre_img = torch.tensor(pre_img / 255.0, dtype=torch.float32).permute(2, 0, 1)\n",
        "        post_img = torch.tensor(post_img / 255.0, dtype=torch.float32).permute(2, 0, 1)\n",
        "\n",
        "        if self.transform:\n",
        "            pre_img = self.transform(pre_img)\n",
        "            post_img = self.transform(post_img)\n",
        "\n",
        "        label = item[\"label\"]\n",
        "        return pre_img, post_img, torch.tensor(label, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\"\"\" Residual Block \"\"\"\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(channels, channels, 3, 1, 1),\n",
        "            nn.InstanceNorm2d(channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(channels, channels, 3, 1, 1),\n",
        "            nn.InstanceNorm2d(channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.block(x)\n",
        "\n",
        "\"\"\" Generator \"\"\"\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=3, label_dim=6):\n",
        "        super().__init__()\n",
        "        self.label_dim = label_dim\n",
        "        self.embed = nn.Embedding(label_dim, 1)\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels + 1, 64, kernel_size=7, stride=1, padding=3),\n",
        "            nn.InstanceNorm2d(64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.down1 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(128),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.down2 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(256),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.down3 = nn.Sequential(\n",
        "            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(512),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.down4 = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=4, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(512),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.res_blocks = nn.Sequential(*[ResidualBlock(512) for _ in range(6)])\n",
        "\n",
        "        self.up1 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(256),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.up2 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(128),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.up3 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.final = nn.Sequential(\n",
        "            nn.Conv2d(64, out_channels, kernel_size=7, stride=1, padding=3),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x, label):\n",
        "        label = self.embed(label).view(-1, 1, 1, 1)\n",
        "        label = label.expand(-1, 1, x.size(2), x.size(3))\n",
        "        x = torch.cat([x, label], dim=1)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.down1(x)\n",
        "        x = self.down2(x)\n",
        "        x = self.down3(x)\n",
        "        x = self.down4(x)\n",
        "        x = self.res_blocks(x)\n",
        "        x = self.up1(x)\n",
        "        x = self.up2(x)\n",
        "        x = self.up3(x)\n",
        "        x = self.final(x)\n",
        "        return x\n",
        "\n",
        "\"\"\" Discriminator \"\"\"\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_channels=3, num_classes=6):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 64, 4, 2, 1),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(64, 128, 4, 2, 1),\n",
        "            nn.InstanceNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(128, 256, 4, 2, 1),\n",
        "            nn.InstanceNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(256, 512, 4, 2, 1),\n",
        "            nn.InstanceNorm2d(512),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "\n",
        "        self.src_head = nn.Conv2d(512, 1, kernel_size=3, stride=1, padding=1)  # Real/fake\n",
        "        self.cls_head = nn.Conv2d(512, num_classes, kernel_size=4)  # Disaster class\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.features(x)\n",
        "        out_src = self.src_head(features)\n",
        "        out_cls = self.cls_head(features).squeeze(3).squeeze(2)\n",
        "        return out_src, out_cls\n",
        "\n",
        "\"\"\" Losses \"\"\"\n",
        "class AdversarialLoss(nn.Module):\n",
        "    def forward(self, D_real_src, D_fake_src):\n",
        "        loss_real = torch.log(D_real_src + 1e-8).mean()\n",
        "        loss_fake = torch.log(1 - D_fake_src + 1e-8).mean()\n",
        "        return -(loss_real + loss_fake)\n",
        "\n",
        "class GeneratorAdversarialLoss(nn.Module):\n",
        "    def forward(self, D_fake_src):\n",
        "        return -torch.log(D_fake_src + 1e-8).mean()\n",
        "\n",
        "class ClassificationLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.loss = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        return self.loss(pred, target)\n",
        "\n",
        "class ReconstructionLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.loss = nn.L1Loss()\n",
        "\n",
        "    def forward(self, recon, original):\n",
        "        return self.loss(recon, original)\n",
        "\n",
        "adversarial_loss = AdversarialLoss()\n",
        "generator_adv_loss = GeneratorAdversarialLoss()\n",
        "classification_loss = ClassificationLoss()\n",
        "reconstruction_loss = ReconstructionLoss()\n",
        "\n",
        "def generator_loss(D_fake_src, D_fake_cls, target_label, x_reconstructed, x_real):\n",
        "    adv_loss = generator_adv_loss(D_fake_src)\n",
        "    cls_loss = classification_loss(D_fake_cls, target_label)\n",
        "    rec_loss = reconstruction_loss(x_reconstructed, x_real)\n",
        "    return adv_loss + cls_loss + 10 * rec_loss\n",
        "\n",
        "def discriminator_loss(D_real_src, D_fake_src, D_real_cls, true_label):\n",
        "    adv_loss = adversarial_loss(D_real_src, D_fake_src)\n",
        "    cls_loss = classification_loss(D_real_cls, true_label)\n",
        "    return adv_loss + cls_loss\n"
      ],
      "metadata": {
        "id": "wyGP7TW8fk1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model_G, model_D, dataloader, optimizer_G, optimizer_D, device, num_epochs=50):\n",
        "    model_G.to(device)\n",
        "    model_D.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (pre_img, post_img, label) in enumerate(dataloader):\n",
        "            pre_img = pre_img.to(device)\n",
        "            post_img = post_img.to(device)\n",
        "            label = label.to(device)\n",
        "\n",
        "            # train discriminator\n",
        "            optimizer_D.zero_grad()\n",
        "\n",
        "            D_real_src, D_real_cls = model_D(post_img)\n",
        "            fake_post = model_G(pre_img, label)\n",
        "            D_fake_src, _ = model_D(fake_post.detach())\n",
        "\n",
        "            d_loss = discriminator_loss(D_real_src, D_fake_src, D_real_cls, label)\n",
        "            d_loss.backward()\n",
        "            optimizer_D.step()\n",
        "\n",
        "            # train generator\n",
        "            optimizer_G.zero_grad()\n",
        "\n",
        "            fake_post = model_G(pre_img, label)\n",
        "            D_fake_src, D_fake_cls = model_D(fake_post)\n",
        "\n",
        "            g_loss = generator_loss(D_fake_src, D_fake_cls, label, fake_post, post_img)\n",
        "            g_loss.backward()\n",
        "            optimizer_G.step()\n",
        "\n",
        "            if i % 10 == 0:\n",
        "                print(f\"Epoch [{epoch+1}/{num_epochs}] Batch [{i}/{len(dataloader)}] D Loss: {d_loss.item():.4f} G Loss: {g_loss.item():.4f}\")\n"
      ],
      "metadata": {
        "id": "eTykjLSgg1-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "df = pd.read_csv(\"/scratch/jsc9862/hold_metadata.csv\")\n",
        "\n",
        "# change?\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
        "])\n",
        "\n",
        "image_dir = \"/scratch/jsc9862/geotiffs/tier1/images\"\n",
        "dataset = DisasterDataset(df, image_dir, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=4)\n",
        "\n",
        "model_G = Generator().to(device)\n",
        "model_D = Discriminator().to(device)\n",
        "optimizer_G = torch.optim.Adam(model_G.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "optimizer_D = torch.optim.Adam(model_D.parameters(), lr=0.0002, betas=(0.5, 0.999))"
      ],
      "metadata": {
        "id": "Q0NIm-8aej-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Uses only a subset of the orininal dataset for training\n",
        "    - Changes train_loader to only hav the first 30 samples\n",
        "    - For debugging purposes\n",
        "\"\"\"\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "subset_indices = list(range(30))\n",
        "subset_dataset = Subset(dataset, subset_indices)\n",
        "\n",
        "subset_train_loader = DataLoader(subset_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
        "\n",
        "dataloader = subset_train_loader"
      ],
      "metadata": {
        "id": "-bAUCn3sjXJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model_G, model_D, dataloader, optimizer_G, optimizer_D, device)"
      ],
      "metadata": {
        "id": "laJnR2Cji6hh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}