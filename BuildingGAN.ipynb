{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef12ba2c-7e6a-4f0a-8d70-4987107d734b",
   "metadata": {},
   "source": [
    "Verify value counts for each disaster type (currently still creating cropped builidng masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac986e51-d695-49c7-819a-4befdfb61685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7788cdc7-be1b-40c8-ac95-482d2e035e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disaster_counts(csv_path, image_dict):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df['filename'] = df['uid'].astype(str) + \"_\" + df['stage'].astype(str) + \".png\"\n",
    "    df = df[df['filename'].isin(image_dict)]\n",
    "    return df['disaster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1b8070a-1082-43c6-9c44-d34c7b02eb79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "disaster\n",
       "flooding      54873\n",
       "wind          52672\n",
       "tsunami       49106\n",
       "earthquake    46764\n",
       "fire          34302\n",
       "volcano        1579\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_disaster_counts(\"building_polygons_metadata.csv\", set(os.listdir(\"./tier1/cropped_square_buildings\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edcee526-5768-4f33-9069-15363a53ffa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image_pairs_and_disasters(csv_path, image_dict):\n",
    "    stage_map = defaultdict(set)\n",
    "    for filename in image_dict:\n",
    "        if filename.endswith(\".png\") and \"_\" in filename:\n",
    "            name = filename[:-4]\n",
    "            parts = name.split(\"_\")\n",
    "            if len(parts) < 2:\n",
    "                continue\n",
    "            uid = \"_\".join(parts[:-1])\n",
    "            stage = parts[-1]\n",
    "            stage_map[uid].add(stage)\n",
    "\n",
    "    paired_uids = {uid for uid, stages in stage_map.items() if {'pre', 'post'}.issubset(stages)}\n",
    "    pair_count = len(paired_uids)\n",
    "    \n",
    "    df = pd.read_csv(csv_path)\n",
    "    df = df[df['uid'].isin(paired_uids)]\n",
    "    disaster_counts = df['disaster'].value_counts()\n",
    "    return pair_count, disaster_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d564ef4-bcb1-40a8-83cd-b90061ee084d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of paired uids (pre + post): 87061\n",
      "\n",
      "Disaster type counts for paired uids:\n",
      " disaster\n",
      "flooding      39178\n",
      "wind          38324\n",
      "tsunami       37420\n",
      "earthquake    32906\n",
      "fire          24848\n",
      "volcano        1446\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "image_dict = set(os.listdir('./tier1/cropped_square_buildings'))\n",
    "pair_count, disaster_counts = analyze_image_pairs_and_disasters(\"building_polygons_metadata.csv\", image_dict)\n",
    "\n",
    "print(\"Number of paired uids (pre + post):\", pair_count)\n",
    "print(\"\\nDisaster type counts for paired uids:\\n\", disaster_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "011e783c-0946-42c4-be6b-2c5a5a4919d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image_pairs_and_damage(csv_path, image_dict):\n",
    "    stage_map = defaultdict(set)\n",
    "    for filename in image_dict:\n",
    "        if filename.endswith(\".png\") and \"_\" in filename:\n",
    "            name = filename[:-4]\n",
    "            parts = name.split(\"_\")\n",
    "            if len(parts) < 2:\n",
    "                continue\n",
    "            uid = \"_\".join(parts[:-1])\n",
    "            stage = parts[-1]\n",
    "            stage_map[uid].add(stage)\n",
    "\n",
    "    paired_uids = {uid for uid, stages in stage_map.items() if {'pre', 'post'}.issubset(stages)}\n",
    "    pair_count = len(paired_uids)\n",
    "    \n",
    "    df = pd.read_csv(csv_path)\n",
    "    df = df[df['uid'].isin(paired_uids)]\n",
    "    damage_counts = df['subtype'].value_counts()\n",
    "    return pair_count, damage_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd2b19c4-fe95-4da1-a771-669a022d1fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of paired uids (pre + post): 87061\n",
      "\n",
      "Damage type counts for paired uids:\n",
      " subtype\n",
      "no-damage        62866\n",
      "destroyed         8122\n",
      "minor-damage      7788\n",
      "major-damage      6844\n",
      "un-classified     1441\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "pair_count, damage_counts = analyze_image_pairs_and_damage(\"building_polygons_metadata.csv\", image_dict)\n",
    "\n",
    "print(\"Number of paired uids (pre + post):\", pair_count)\n",
    "print(\"\\nDamage type counts for paired uids:\\n\", damage_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad88787-ae77-4cec-9c74-19e7481b08e4",
   "metadata": {},
   "source": [
    "BuildingGAN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b027093-8bcb-4e8c-86b6-e9e5e91b7390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import argparse\n",
    "from types import SimpleNamespace\n",
    "from tqdm import tqdm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ca90917-2199-47c6-a5fe-45eee3a8902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisasterBuildingDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform or transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "        ])\n",
    "        \n",
    "        self.disaster_to_idx = {\n",
    "            'flooding': 0,\n",
    "            'wind': 1,\n",
    "            'earthquake': 2,\n",
    "            'tsunami': 3,\n",
    "            'fire': 4,\n",
    "            'volcano': 5\n",
    "        }\n",
    "\n",
    "        self.pairs = []\n",
    "        print(\"Scanning image directory and constructing pairs...\")\n",
    "\n",
    "        # Extract base_uid from df for later matching\n",
    "        df['base_uid'] = df['uid'].apply(lambda x: x.split('_')[0])\n",
    "        df = df.set_index(['base_uid', 'stage'])\n",
    "\n",
    "        # Collect all pngs and group by base_uid\n",
    "        images = [f for f in os.listdir(img_dir) if f.endswith('.png')]\n",
    "        image_groups = {}\n",
    "\n",
    "        for fname in images:\n",
    "            name_part = fname.replace('.png', '')\n",
    "            uid_parts = name_part.split('_')\n",
    "            if len(uid_parts) != 2:\n",
    "                continue  # skip malformed filenames\n",
    "            base_uid, stage = uid_parts\n",
    "            image_groups.setdefault(base_uid, {})[stage] = fname\n",
    "\n",
    "        for base_uid, group in image_groups.items():\n",
    "            if 'pre' in group and 'post' in group:\n",
    "                try:\n",
    "                    pre_row = df.loc[(base_uid, 'pre')]\n",
    "                    post_row = df.loc[(base_uid, 'post')]\n",
    "    \n",
    "                    # Filter out post images with no damage or unclassified\n",
    "                    if post_row['subtype'] in ['no-damage', 'un-classified', 'minor-damage']:\n",
    "                        continue\n",
    "    \n",
    "                    disaster_type = post_row['disaster']\n",
    "                    image_id = post_row['image_id']\n",
    "                    \n",
    "                    if disaster_type in self.disaster_to_idx:\n",
    "                        self.pairs.append({\n",
    "                            'pre_uid': group['pre'].replace('.png', ''),\n",
    "                            'post_uid': group['post'].replace('.png', ''),\n",
    "                            'disaster_type': disaster_type,\n",
    "                            'image_id': image_id\n",
    "                        })\n",
    "                except KeyError:\n",
    "                    continue  # skip if metadata is missing\n",
    "\n",
    "\n",
    "        print(f\"Total image pairs constructed: {len(self.pairs)}\")\n",
    "        self.num_disaster_types = len(self.disaster_to_idx)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        pair = self.pairs[idx]\n",
    "        \n",
    "        pre_path = os.path.join(self.img_dir, f\"{pair['pre_uid']}.png\")\n",
    "        post_path = os.path.join(self.img_dir, f\"{pair['post_uid']}.png\")\n",
    "        \n",
    "        pre_img = Image.open(pre_path).convert('RGB')\n",
    "        post_img = Image.open(post_path).convert('RGB')\n",
    "        pre_img = np.array(pre_img).astype(np.float32) / 255.0\n",
    "        post_img = np.array(post_img).astype(np.float32) / 255.0\n",
    "        \n",
    "        # Convert to torch tensors with CxHxW\n",
    "        pre_img = torch.from_numpy(pre_img).permute(2, 0, 1)\n",
    "        post_img = torch.from_numpy(post_img).permute(2, 0, 1)\n",
    "        \n",
    "        if self.transform:\n",
    "            pre_img = self.transform(pre_img)\n",
    "            post_img = self.transform(post_img)\n",
    "        \n",
    "        # one-hot encode label\n",
    "        disaster_idx = self.disaster_to_idx[pair['disaster_type']]\n",
    "        disaster_label = torch.zeros(self.num_disaster_types)\n",
    "        disaster_label[disaster_idx] = 1.0\n",
    "        \n",
    "        return {\n",
    "            'pre_image': pre_img,\n",
    "            'post_image': post_img,\n",
    "            'disaster_type': disaster_label,  # one-hot encoded\n",
    "            'disaster_idx': disaster_idx,     # index\n",
    "            'image_id': pair['image_id']\n",
    "        } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6deb8380-7ddc-49c8-b02b-3e7203e25734",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels, kernel_size=3, padding=1, stride=1),\n",
    "            nn.InstanceNorm2d(channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channels, channels, kernel_size=3, padding=1, stride=1),\n",
    "            nn.InstanceNorm2d(channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.conv_block(x)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_channels=9):  # 3 for RGB + 6 for disaster label ## CHANGE FOR DIFFERENT LABELING TECHNIQUE\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        # Layer 1\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 64, kernel_size=7, padding=3, stride=1),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Layer 2\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=4, padding=1, stride=2),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Layer 3\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=4, padding=1, stride=2),\n",
    "            nn.InstanceNorm2d(256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Layers 4-9: Residual blocks\n",
    "        self.residual_blocks = nn.Sequential(\n",
    "            *[ResidualBlock(256) for _ in range(6)]\n",
    "        )\n",
    "        \n",
    "        # Layer 10: Deconv\n",
    "        self.layer10 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Layer 11: Deconv\n",
    "        self.layer11 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Layer 12: Output layer\n",
    "        self.layer12 = nn.Sequential(\n",
    "            nn.Conv2d(64, 3, kernel_size=7, padding=3, stride=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, disaster_label):\n",
    "        # Concatenate image with label\n",
    "        disaster_label = disaster_label.view(disaster_label.size(0), -1, 1, 1)\n",
    "        disaster_label = disaster_label.repeat(1, 1, x.size(2), x.size(3))\n",
    "        x = torch.cat([x, disaster_label], dim=1)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.residual_blocks(x)\n",
    "        x = self.layer10(x)\n",
    "        x = self.layer11(x)\n",
    "        x = self.layer12(x)\n",
    "        \n",
    "        return x \n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num_disaster_types=6): ## CHANGE FOR DIFFERENT LABELING TECHNIQUE\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        # Layer 1\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Layer 2\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Layer 3\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Layer 4\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Layer 5a - source classification (real/fake)\n",
    "        self.source_layer = nn.Sequential(\n",
    "            nn.Conv2d(512, 1, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "        \n",
    "        # Layer 5b - disaster type classification\n",
    "        self.classification_layer = nn.Sequential(\n",
    "            nn.Conv2d(512, num_disaster_types, kernel_size=4)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        features = self.layer4(x)\n",
    "        \n",
    "        # source classification\n",
    "        source_pred = self.source_layer(features)\n",
    "        \n",
    "        # disaster type classification\n",
    "        class_pred = self.classification_layer(features)\n",
    "        class_pred = class_pred.view(class_pred.size(0), -1)\n",
    "        \n",
    "        return source_pred, class_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d9b17df-1396-424d-9828-3001fa51f37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GANLoss, self).__init__()\n",
    "        self.register_buffer('real_label', torch.tensor(1.0))\n",
    "        self.register_buffer('fake_label', torch.tensor(0.0))\n",
    "        self.loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def __call__(self, prediction, target_is_real):\n",
    "        target = self.real_label if target_is_real else self.fake_label\n",
    "        target = target.expand_as(prediction)\n",
    "        return self.loss(prediction, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f468c385-3913-40e9-950d-794f12f7a82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    df = pd.read_csv(args.csv_file)\n",
    "\n",
    "    dataset = DisasterBuildingDataset(df, args.img_dir)\n",
    "    dataloader = DataLoader(dataset,\n",
    "                            batch_size=args.batch_size,\n",
    "                            shuffle=True,\n",
    "                            num_workers=4)\n",
    "\n",
    "    # Initialize models\n",
    "    generator = Generator()\n",
    "    discriminator = Discriminator(num_disaster_types=dataset.num_disaster_types)\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(f\"Using {torch.cuda.device_count()} GPUs with DataParallel.\")\n",
    "        generator = nn.DataParallel(generator)\n",
    "        discriminator = nn.DataParallel(discriminator)\n",
    "\n",
    "    generator = generator.to(device)\n",
    "    discriminator = discriminator.to(device)\n",
    "\n",
    "    g_optimizer = optim.Adam(generator.parameters(), lr=args.lr, betas=(0.5, 0.999))\n",
    "    d_optimizer = optim.Adam(discriminator.parameters(), lr=args.lr, betas=(0.5, 0.999))\n",
    "\n",
    "    gan_loss = GANLoss().to(device)\n",
    "    cls_loss = nn.CrossEntropyLoss()\n",
    "    rec_loss = nn.L1Loss()\n",
    "\n",
    "    lambda_cls = 1\n",
    "    lambda_rec = 10\n",
    "\n",
    "    # Resume from latest checkpoint if it exists\n",
    "    checkpoint_path = 'checkpoints/BuildingGAN_latest3.pth'\n",
    "    start_epoch = 0\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        print(f\"Resuming from {checkpoint_path}...\")\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "\n",
    "        if isinstance(generator, nn.DataParallel):\n",
    "            generator.module.load_state_dict(checkpoint['generator_state_dict'])\n",
    "            discriminator.module.load_state_dict(checkpoint['discriminator_state_dict'])\n",
    "        else:\n",
    "            generator.load_state_dict(checkpoint['generator_state_dict'])\n",
    "            discriminator.load_state_dict(checkpoint['discriminator_state_dict'])\n",
    "\n",
    "        g_optimizer.load_state_dict(checkpoint['g_optimizer_state_dict'])\n",
    "        d_optimizer.load_state_dict(checkpoint['d_optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        print(f\"Resumed from epoch {start_epoch}\")\n",
    "\n",
    "    for epoch in range(start_epoch, args.epochs):\n",
    "        progress_bar = tqdm(dataloader, desc=f'Epoch {epoch+1}/{args.epochs}')\n",
    "        for batch in progress_bar:\n",
    "            real_images     = batch['post_image'].to(device)\n",
    "            pre_images      = batch['pre_image'].to(device)\n",
    "            disaster_onehot = batch['disaster_type'].to(device)\n",
    "            disaster_idx    = batch['disaster_idx'].to(device)\n",
    "\n",
    "            d_optimizer.zero_grad()\n",
    "            real_src_pred, real_cls_pred = discriminator(real_images)\n",
    "            d_real_src_loss = gan_loss(real_src_pred, True)\n",
    "            d_real_cls_loss = cls_loss(real_cls_pred, disaster_idx)\n",
    "\n",
    "            fake_images = generator(pre_images, disaster_onehot)\n",
    "            fake_src_pred, _ = discriminator(fake_images.detach())\n",
    "            d_fake_src_loss = gan_loss(fake_src_pred, False)\n",
    "\n",
    "            d_loss = -(-d_real_src_loss - d_fake_src_loss) + lambda_cls * d_real_cls_loss\n",
    "            d_loss.backward()\n",
    "            d_optimizer.step()\n",
    "\n",
    "            g_optimizer.zero_grad()\n",
    "            fake_src_pred, fake_cls_pred = discriminator(fake_images)\n",
    "            g_adv_loss = gan_loss(fake_src_pred, True)\n",
    "            g_cls_loss = cls_loss(fake_cls_pred, disaster_idx)\n",
    "\n",
    "            rec_images = generator(fake_images, disaster_onehot)\n",
    "            g_rec_loss = rec_loss(rec_images, real_images)\n",
    "\n",
    "            g_loss = g_adv_loss + lambda_cls * g_cls_loss + lambda_rec * g_rec_loss\n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "\n",
    "            progress_bar.set_postfix({\n",
    "                'D Loss': f'{d_loss.item():.4f}',\n",
    "                'G Loss': f'{g_loss.item():.4f}',\n",
    "                'Rec Loss': f'{g_rec_loss.item():.4f}'\n",
    "            })\n",
    "\n",
    "        # Save model checkpoint\n",
    "        os.makedirs('checkpoints', exist_ok=True)\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'generator_state_dict': generator.module.state_dict() if isinstance(generator, nn.DataParallel) else generator.state_dict(),\n",
    "            'discriminator_state_dict': discriminator.module.state_dict() if isinstance(discriminator, nn.DataParallel) else discriminator.state_dict(),\n",
    "            'g_optimizer_state_dict': g_optimizer.state_dict(),\n",
    "            'd_optimizer_state_dict': d_optimizer.state_dict(),\n",
    "        }, checkpoint_path)\n",
    "\n",
    "        # Save every 15 epoch model checkpoint\n",
    "        if (epoch + 1) % 15 == 0:\n",
    "            extra_path = f'checkpoints/BuildingGAN_epoch{epoch + 1}.pth'\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'generator_state_dict': generator.module.state_dict() if isinstance(generator, nn.DataParallel) else generator.state_dict(),\n",
    "                'discriminator_state_dict': discriminator.module.state_dict() if isinstance(discriminator, nn.DataParallel) else discriminator.state_dict(),\n",
    "                'g_optimizer_state_dict': g_optimizer.state_dict(),\n",
    "                'd_optimizer_state_dict': d_optimizer.state_dict(),\n",
    "            }, extra_path)\n",
    "            print(f\"Additional checkpoint saved at {extra_path}\")\n",
    "\n",
    "        print(f\"Checkpoint saved at epoch {epoch+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a4545f8-a1e6-40f3-a621-8fcacc6ced95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning image directory and constructing pairs...\n",
      "Total image pairs constructed: 14966\n",
      "Using 2 GPUs with DataParallel.\n",
      "Resuming from checkpoints/BuildingGAN_latest3.pth...\n",
      "Resumed from epoch 335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 336/1000: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 117/117 [02:12<00:00,  1.13s/it, D Loss=3.1996, G Loss=1.6784, Rec Loss=0.0861]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 337/1000: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 117/117 [02:06<00:00,  1.09s/it, D Loss=3.2793, G Loss=1.6635, Rec Loss=0.0878]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 338/1000: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 117/117 [02:06<00:00,  1.08s/it, D Loss=3.2872, G Loss=1.6412, Rec Loss=0.0859]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 339/1000: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 117/117 [02:06<00:00,  1.08s/it, D Loss=2.8790, G Loss=1.7286, Rec Loss=0.0883]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 340/1000: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 117/117 [02:06<00:00,  1.08s/it, D Loss=3.2613, G Loss=1.7836, Rec Loss=0.0869]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 341/1000: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 117/117 [02:06<00:00,  1.08s/it, D Loss=3.6449, G Loss=2.0101, Rec Loss=0.0884]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 342/1000: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 117/117 [02:07<00:00,  1.09s/it, D Loss=3.3468, G Loss=1.6919, Rec Loss=0.0923]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 343/1000: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 117/117 [02:07<00:00,  1.09s/it, D Loss=3.3489, G Loss=1.5567, Rec Loss=0.0880]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 344/1000: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 117/117 [02:06<00:00,  1.08s/it, D Loss=3.2260, G Loss=1.5834, Rec Loss=0.0875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 345/1000: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 117/117 [02:06<00:00,  1.08s/it, D Loss=3.3804, G Loss=1.7023, Rec Loss=0.0920]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional checkpoint saved at checkpoints/BuildingGAN_epoch345.pth\n",
      "Checkpoint saved at epoch 345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 346/1000: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 117/117 [02:07<00:00,  1.09s/it, D Loss=3.3290, G Loss=1.8146, Rec Loss=0.0888]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 347/1000: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 117/117 [02:07<00:00,  1.09s/it, D Loss=3.2592, G Loss=1.5888, Rec Loss=0.0841]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 348/1000: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 117/117 [02:07<00:00,  1.09s/it, D Loss=3.2350, G Loss=1.7145, Rec Loss=0.0839]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 349/1000: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 117/117 [02:07<00:00,  1.09s/it, D Loss=3.2295, G Loss=1.6436, Rec Loss=0.0878]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 350/1000:  38%|█████████████████████████████████████████▏                                                                 | 45/117 [00:50<01:21,  1.13s/it, D Loss=3.2136, G Loss=1.4074, Rec Loss=0.0861]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m args = SimpleNamespace(\n\u001b[32m      2\u001b[39m         csv_file=\u001b[33m'\u001b[39m\u001b[33m./building_polygons_metadata.csv\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      3\u001b[39m         img_dir=\u001b[33m'\u001b[39m\u001b[33m./tier1/cropped_square_buildings\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m      6\u001b[39m         lr=\u001b[32m0.00001\u001b[39m,\n\u001b[32m      7\u001b[39m     )\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m train(args)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 84\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(args)\u001b[39m\n\u001b[32m     82\u001b[39m     g_loss = g_adv_loss + lambda_cls * g_cls_loss + lambda_rec * g_rec_loss\n\u001b[32m     83\u001b[39m     g_loss.backward()\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     g_optimizer.step()\n\u001b[32m     86\u001b[39m     progress_bar.set_postfix({\n\u001b[32m     87\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mD Loss\u001b[39m\u001b[33m'\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00md_loss.item()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m,\n\u001b[32m     88\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mG Loss\u001b[39m\u001b[33m'\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mg_loss.item()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m,\n\u001b[32m     89\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mRec Loss\u001b[39m\u001b[33m'\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mg_rec_loss.item()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m     90\u001b[39m     })\n\u001b[32m     92\u001b[39m \u001b[38;5;66;03m# Save model checkpoint\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ext3/miniconda3/lib/python3.12/site-packages/torch/optim/optimizer.py:493\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    488\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    489\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    490\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    491\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m out = func(*args, **kwargs)\n\u001b[32m    494\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    496\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ext3/miniconda3/lib/python3.12/site-packages/torch/optim/optimizer.py:91\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     90\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     ret = func(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     93\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ext3/miniconda3/lib/python3.12/site-packages/torch/optim/adam.py:244\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    232\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    234\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    235\u001b[39m         group,\n\u001b[32m    236\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    241\u001b[39m         state_steps,\n\u001b[32m    242\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m     adam(\n\u001b[32m    245\u001b[39m         params_with_grad,\n\u001b[32m    246\u001b[39m         grads,\n\u001b[32m    247\u001b[39m         exp_avgs,\n\u001b[32m    248\u001b[39m         exp_avg_sqs,\n\u001b[32m    249\u001b[39m         max_exp_avg_sqs,\n\u001b[32m    250\u001b[39m         state_steps,\n\u001b[32m    251\u001b[39m         amsgrad=group[\u001b[33m\"\u001b[39m\u001b[33mamsgrad\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    252\u001b[39m         has_complex=has_complex,\n\u001b[32m    253\u001b[39m         beta1=beta1,\n\u001b[32m    254\u001b[39m         beta2=beta2,\n\u001b[32m    255\u001b[39m         lr=group[\u001b[33m\"\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    256\u001b[39m         weight_decay=group[\u001b[33m\"\u001b[39m\u001b[33mweight_decay\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    257\u001b[39m         eps=group[\u001b[33m\"\u001b[39m\u001b[33meps\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    258\u001b[39m         maximize=group[\u001b[33m\"\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    259\u001b[39m         foreach=group[\u001b[33m\"\u001b[39m\u001b[33mforeach\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    260\u001b[39m         capturable=group[\u001b[33m\"\u001b[39m\u001b[33mcapturable\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    261\u001b[39m         differentiable=group[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    262\u001b[39m         fused=group[\u001b[33m\"\u001b[39m\u001b[33mfused\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    263\u001b[39m         grad_scale=\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mgrad_scale\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    264\u001b[39m         found_inf=\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfound_inf\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    265\u001b[39m     )\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ext3/miniconda3/lib/python3.12/site-packages/torch/optim/optimizer.py:154\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ext3/miniconda3/lib/python3.12/site-packages/torch/optim/adam.py:876\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    873\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    874\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m876\u001b[39m func(\n\u001b[32m    877\u001b[39m     params,\n\u001b[32m    878\u001b[39m     grads,\n\u001b[32m    879\u001b[39m     exp_avgs,\n\u001b[32m    880\u001b[39m     exp_avg_sqs,\n\u001b[32m    881\u001b[39m     max_exp_avg_sqs,\n\u001b[32m    882\u001b[39m     state_steps,\n\u001b[32m    883\u001b[39m     amsgrad=amsgrad,\n\u001b[32m    884\u001b[39m     has_complex=has_complex,\n\u001b[32m    885\u001b[39m     beta1=beta1,\n\u001b[32m    886\u001b[39m     beta2=beta2,\n\u001b[32m    887\u001b[39m     lr=lr,\n\u001b[32m    888\u001b[39m     weight_decay=weight_decay,\n\u001b[32m    889\u001b[39m     eps=eps,\n\u001b[32m    890\u001b[39m     maximize=maximize,\n\u001b[32m    891\u001b[39m     capturable=capturable,\n\u001b[32m    892\u001b[39m     differentiable=differentiable,\n\u001b[32m    893\u001b[39m     grad_scale=grad_scale,\n\u001b[32m    894\u001b[39m     found_inf=found_inf,\n\u001b[32m    895\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ext3/miniconda3/lib/python3.12/site-packages/torch/optim/adam.py:685\u001b[39m, in \u001b[36m_multi_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[39m\n\u001b[32m    682\u001b[39m     torch._foreach_addcdiv_(device_params, device_exp_avgs, exp_avg_sq_sqrt)\n\u001b[32m    683\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    684\u001b[39m     bias_correction1 = [\n\u001b[32m--> \u001b[39m\u001b[32m685\u001b[39m         \u001b[32m1\u001b[39m - beta1 ** _get_value(step) \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m device_state_steps\n\u001b[32m    686\u001b[39m     ]\n\u001b[32m    687\u001b[39m     bias_correction2 = [\n\u001b[32m    688\u001b[39m         \u001b[32m1\u001b[39m - beta2 ** _get_value(step) \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m device_state_steps\n\u001b[32m    689\u001b[39m     ]\n\u001b[32m    691\u001b[39m     step_size = _stack_if_compiling([(lr / bc) * -\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m bc \u001b[38;5;129;01min\u001b[39;00m bias_correction1])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ext3/miniconda3/lib/python3.12/site-packages/torch/optim/optimizer.py:106\u001b[39m, in \u001b[36m_get_value\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x.item() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, torch.Tensor) \u001b[38;5;28;01melse\u001b[39;00m x\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "args = SimpleNamespace(\n",
    "        csv_file='./building_polygons_metadata.csv',\n",
    "        img_dir='./tier1/cropped_square_buildings',\n",
    "        epochs=1000,\n",
    "        batch_size=128,\n",
    "        lr=0.00001,\n",
    "    )\n",
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74e272c-3f41-45db-a504-acaad4683b04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Custom Env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
