{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-08 16:21:48.854891: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-08 16:21:49.823784: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-08 16:21:50.606310: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746735711.200515    5887 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746735711.367272    5887 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746735712.979851    5887 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746735712.979894    5887 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746735712.979896    5887 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746735712.979899    5887 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-08 16:21:53.129560: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97851\n"
     ]
    }
   ],
   "source": [
    "image_dir = '/scratch/ac9743/pytorch-example/tier1/images'\n",
    "label_dir = '/scratch/ac9743/pytorch-example/tier1/labels'\n",
    "\n",
    "df = pd.read_csv(\"/scratch/ac9743/pytorch-example/tier1.csv\")\n",
    "\n",
    "# For the GAN we only care about post disaster images\n",
    "filtered_df = df[\n",
    "    (df[\"stage\"] == \"post\") &\n",
    "    (df[\"feature_type\"] == \"building\")\n",
    "]\n",
    "\n",
    "num_disaster_types = len(filtered_df[\"disaster_type\"].unique())\n",
    "\n",
    "print(len(filtered_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import tifffile\n",
    "from PIL import Image, ImageDraw\n",
    "from shapely import wkt\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, metadata_df, image_dir, label_dir, image_size=(256, 256)): \n",
    "        self.metadata_df = metadata_df\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.image_size = image_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata_df)\n",
    "\n",
    "    def preprocess_image(self, image):\n",
    "        # Normalize image\n",
    "        image = image.resize(self.image_size)\n",
    "        image = np.array(image).astype(np.float32) / 255.0  # Normalize to [0, 1]\n",
    "        return torch.from_numpy(image).permute(2, 0, 1)  # Convert to tensor and rearrange dims to [C, H, W]\n",
    "\n",
    "    def preprocess_mask(self, mask):\n",
    "        mask = mask.resize(self.image_size)\n",
    "        mask = np.array(mask).astype(np.float32)\n",
    "        return torch.from_numpy(mask).unsqueeze(0)  # Shape [1, H, W]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.metadata_df.iloc[idx]\n",
    "        img_path = os.path.join(self.image_dir, row[\"image_filename\"])\n",
    "        label_path = os.path.join(self.label_dir, row[\"label_filename\"])\n",
    "\n",
    "        # Load image using tifffile\n",
    "        image = tifffile.imread(img_path)\n",
    "        if image.dtype == np.int16:\n",
    "            image = np.clip(image, 0, 255).astype(np.uint8)\n",
    "        image = Image.fromarray(image).convert(\"RGB\")\n",
    "\n",
    "        # Load mask from polygons\n",
    "        mask = Image.new(\"L\", self.image_size, 0)\n",
    "        draw = ImageDraw.Draw(mask)\n",
    "\n",
    "        with open(label_path, 'r') as f:\n",
    "            label_data = json.load(f)\n",
    "\n",
    "        features = label_data.get(\"features\", {}).get(\"lng_lat\", [])\n",
    "        for feature in features:\n",
    "            wkt_str = feature.get(\"wkt\")\n",
    "            try:\n",
    "                poly = wkt.loads(wkt_str)\n",
    "                if poly.is_valid:\n",
    "                    coords = [(x, y) for x, y in poly.exterior.coords]\n",
    "                    draw.polygon(coords, outline=1, fill=1)\n",
    "            except Exception as e:\n",
    "                print(f\"Polygon error in {label_path}: {e}\")\n",
    "\n",
    "        # Preprocess image and mask\n",
    "        image_tensor = self.preprocess_image(image)\n",
    "        mask_tensor = self.preprocess_mask(mask)\n",
    "\n",
    "        return {\n",
    "            \"image\": image_tensor,        \n",
    "            \"mask\": mask_tensor,          \n",
    "            \"stage\": row[\"stage\"],\n",
    "            \"disaster_type\": row[\"disaster_type\"]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(filtered_df, image_dir, label_dir)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ac9743/.local/lib/python3.9/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n",
      "E0000 00:00:1746735769.229576    5887 cuda_executor.cc:1228] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1746735769.233423    5887 gpu_device.cc:2341] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "discriminator = keras.Sequential([\n",
    "    keras.Input(shape=(256, 256, 3)),\n",
    "    \n",
    "    layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"),  # 128x128\n",
    "    layers.LeakyReLU(alpha=0.2),\n",
    "    \n",
    "    layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),  # 64x64\n",
    "    layers.LeakyReLU(alpha=0.2),\n",
    "    \n",
    "    layers.Conv2D(256, kernel_size=4, strides=2, padding=\"same\"),  # 32x32\n",
    "    layers.LeakyReLU(alpha=0.2),\n",
    "    \n",
    "    layers.Conv2D(512, kernel_size=4, strides=2, padding=\"same\"),  # 16x16\n",
    "    layers.LeakyReLU(alpha=0.2),\n",
    "    \n",
    "    layers.Conv2D(512, kernel_size=4, strides=2, padding=\"same\"),  # 8x8\n",
    "    layers.LeakyReLU(alpha=0.2),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(1, activation=\"sigmoid\")  # Or linear if using WGAN\n",
    "], name=\"discriminator\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 128\n",
    "\n",
    "generator = keras.Sequential([\n",
    "    keras.Input(shape=(latent_dim,)),\n",
    "    layers.Dense(8 * 8 * 256),\n",
    "    layers.Reshape((8, 8, 256)),\n",
    "    \n",
    "    # Increase the number of upsampling layers to output 256x256\n",
    "    layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"),  # 16x16\n",
    "    layers.LeakyReLU(alpha=0.2),\n",
    "    \n",
    "    layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"),  # 32x32\n",
    "    layers.LeakyReLU(alpha=0.2),\n",
    "    \n",
    "    layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding=\"same\"),   # 64x64\n",
    "    layers.LeakyReLU(alpha=0.2),\n",
    "    \n",
    "    layers.Conv2DTranspose(32, kernel_size=4, strides=2, padding=\"same\"),   # 128x128\n",
    "    layers.LeakyReLU(alpha=0.2),\n",
    "    \n",
    "    layers.Conv2DTranspose(16, kernel_size=4, strides=2, padding=\"same\"),   # 256x256\n",
    "    layers.LeakyReLU(alpha=0.2),\n",
    "    \n",
    "    layers.Conv2D(3, kernel_size=3, activation=\"tanh\", padding=\"same\")  # Output 256x256x3\n",
    "], name=\"generator\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super().__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
    "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(GAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.d_loss_metric, self.g_loss_metric]\n",
    "\n",
    "    def train_step(self, real_images):\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(\n",
    "            shape=(batch_size, self.latent_dim))\n",
    "        generated_images = self.generator(random_latent_vectors)\n",
    "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))],\n",
    "            axis=0\n",
    "        )\n",
    "\n",
    "        # Add noise to discriminator labels to make it's job harder\n",
    "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        random_latent_vectors = tf.random.normal(\n",
    "            shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(\n",
    "                self.generator(random_latent_vectors))\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(\n",
    "            zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        return {\"d_loss\": self.d_loss_metric.result(),\n",
    "                \"g_loss\": self.g_loss_metric.result()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, num_img=3, latent_dim=128):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
    "        generated_images = self.model.generator(random_latent_vectors)\n",
    "    \n",
    "        generated_images = (generated_images + 1) * 127.5\n",
    "\n",
    "        # Create a directory to store generated images if it doesn't exist\n",
    "        os.makedirs(\"generated_images_256\", exist_ok=True)\n",
    "\n",
    "        for i in range(self.num_img):\n",
    "            img = keras.utils.array_to_img(generated_images[i])\n",
    "            img.save(f\"generated_images_256/generated_img_{epoch:03d}_{i}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
    "\n",
    "gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0002),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 25\n",
    "batch_size = 32\n",
    "\n",
    "# Converting to a tensor dataframe because GAN model is in tensor/keras\n",
    "\n",
    "def preprocess_image_tf(item):\n",
    "    return tf.convert_to_tensor(item[\"image\"], dtype=tf.float32)\n",
    "\n",
    "tf_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: ({\"image\": tf.transpose(d[\"image\"], (1, 2, 0))} for d in dataset),\n",
    "    output_signature={\n",
    "        \"image\": tf.TensorSpec(shape=(256, 256, 3), dtype=tf.float32),\n",
    "    }\n",
    ")\n",
    "\n",
    "tf_dataset = tf_dataset.map(lambda x: x[\"image\"]).batch(batch_size)\n",
    "tf_dataset = tf_dataset.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = generator(tf.random.normal((1, latent_dim)))\n",
    "_ = discriminator(tf.random.normal((1, 256, 256, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored from ./checkpoints/ckpt-39\n",
      "Epoch 1/25\n",
      "\u001b[1m  64/3057\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:16:56\u001b[0m 6s/step - d_loss: 0.1914 - g_loss: 3.5163"
     ]
    }
   ],
   "source": [
    "checkpoint = tf.train.Checkpoint(\n",
    "    generator=generator,\n",
    "    discriminator=discriminator,\n",
    "    gan=gan,\n",
    "    g_optimizer=gan.g_optimizer,  # Use the optimizers from your GAN model\n",
    "    d_optimizer=gan.d_optimizer\n",
    ")\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(checkpoint, './checkpoints', max_to_keep=3)\n",
    "\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    checkpoint.restore(ckpt_manager.latest_checkpoint)\n",
    "    print(\"Restored from\", ckpt_manager.latest_checkpoint)\n",
    "else:\n",
    "    print(\"Initializing from scratch.\")\n",
    "\n",
    "class CheckpointSaver(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        ckpt_manager.save()\n",
    "    \n",
    "steps_per_epoch = len(dataset) // batch_size \n",
    "\n",
    "gan.fit(\n",
    "    tf_dataset,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    callbacks=[GANMonitor(num_img=10, latent_dim=latent_dim), CheckpointSaver()]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5 (main, Sep 11 2023, 08:19:27) [Clang 14.0.6 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "6b606232894312858dfedcbddaaa9a588838a8d3d5566ee72dff526b5f24a253"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
