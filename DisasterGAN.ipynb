{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19a86d58-bc7c-42e4-ad22-7920b5545649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import argparse\n",
    "from types import SimpleNamespace\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0eb5d448-213a-4870-8a18-9e5af476013f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisasterDataset(Dataset):\n",
    "    def __init__(self, dataframe, img_dir, transform=None):\n",
    "        \"\"\"\n",
    "            dataframe: Pandas DataFrame containing image information (collected in xbd_to_df.ipynb)\n",
    "            img_dir: directory containing the images\n",
    "            transform: optional transform for future use\n",
    "        \"\"\"\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform or transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "        ])\n",
    "        \n",
    "        # Collapse disaster_type to uniform (taken from image file path)\n",
    "        dataframe[\"disaster_type\"] = dataframe[\"disaster_type\"].replace({\n",
    "            \"michael\": \"hurricane\",\n",
    "            \"harvey\": \"hurricane\",\n",
    "            \"florence\": \"hurricane\",\n",
    "            \"matthew\": \"hurricane\",\n",
    "            \"flooding\": \"hurricane\",\n",
    "            \"wildfire\": \"fire\"\n",
    "        })\n",
    "        \n",
    "        # Only include post images with major damage or destroyed\n",
    "        filtered_df = dataframe[\n",
    "            (dataframe[\"stage\"] == \"post\") &\n",
    "            (dataframe[\"subtype\"].isin([\"major-damage\", \"destroyed\"]))\n",
    "        ]\n",
    "        \n",
    "        # Integers mapping for labels\n",
    "        self.disaster_to_idx = {\n",
    "            'hurricane': 0,\n",
    "            'fire': 1,\n",
    "            'earthquake': 2,\n",
    "            'tsunami': 3,\n",
    "            'volcano': 4\n",
    "        }\n",
    "        \n",
    "        # Find image pairs of pre and post images with same id\n",
    "        self.pairs = []\n",
    "        processed_ids = set()\n",
    "        \n",
    "        for _, row in dataframe.iterrows():\n",
    "            img_id = row[\"image_id\"]\n",
    "            if img_id in processed_ids:\n",
    "                continue\n",
    "                \n",
    "            pre_img = dataframe[(dataframe[\"image_id\"] == img_id) & (dataframe[\"stage\"] == \"pre\")]\n",
    "            post_img = dataframe[(dataframe[\"image_id\"] == img_id) & (dataframe[\"stage\"] == \"post\")]\n",
    "            \n",
    "            if len(pre_img) > 0 and len(post_img) > 0:\n",
    "                disaster_type = post_img.iloc[0][\"disaster_type\"]\n",
    "                if disaster_type in self.disaster_to_idx:\n",
    "                    self.pairs.append({\n",
    "                        'id': img_id,\n",
    "                        'pre_path': f\"{img_id}_pre_disaster.tif\",\n",
    "                        'post_path': f\"{img_id}_post_disaster.tif\",\n",
    "                        'disaster_type': disaster_type\n",
    "                    })\n",
    "            processed_ids.add(img_id)\n",
    "        \n",
    "        # Total number of disaster types for one-hot encoding\n",
    "        self.num_disaster_types = len(self.disaster_to_idx)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        pair = self.pairs[idx]\n",
    "        \n",
    "        pre_path = os.path.join(self.img_dir, pair['pre_path'])\n",
    "        post_path = os.path.join(self.img_dir, pair['post_path'])\n",
    "\n",
    "        pre_img = tiff.imread(pre_path)\n",
    "        post_img = tiff.imread(post_path)\n",
    "        \n",
    "        # Ensure images are HxWxC\n",
    "        pre_img = np.expand_dims(pre_img, axis=-1) if pre_img.ndim == 2 else pre_img\n",
    "        post_img = np.expand_dims(post_img, axis=-1) if post_img.ndim == 2 else post_img\n",
    "        \n",
    "        # Normalize to [0, 1]\n",
    "        pre_img = pre_img.astype(np.float32) / 255.0\n",
    "        post_img = post_img.astype(np.float32) / 255.0\n",
    "        \n",
    "        # torch tensors with CxHxW\n",
    "        pre_img = torch.from_numpy(pre_img).permute(2, 0, 1)\n",
    "        post_img = torch.from_numpy(post_img).permute(2, 0, 1)\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            pre_img = self.transform(pre_img)\n",
    "            post_img = self.transform(post_img)\n",
    "        \n",
    "        # one-hot encode label\n",
    "        disaster_idx = self.disaster_to_idx[pair['disaster_type']]\n",
    "        disaster_label = torch.zeros(self.num_disaster_types)\n",
    "        disaster_label[disaster_idx] = 1.0\n",
    "        \n",
    "        return {\n",
    "            'pre_image': pre_img,\n",
    "            'post_image': post_img,\n",
    "            'disaster_type': disaster_label,  # one-hot encoded\n",
    "            'disaster_idx': disaster_idx,     # index\n",
    "            'image_id': pair['id']\n",
    "        } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5483b809-ba98-4cdb-9e02-11c8807702d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels, kernel_size=3, padding=1, stride=1),\n",
    "            nn.InstanceNorm2d(channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channels, channels, kernel_size=3, padding=1, stride=1),\n",
    "            nn.InstanceNorm2d(channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.conv_block(x)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_channels=8):  # 3 for RGB + 5 for disaster label ## CHANGE FOR DIFFERENT LABELING TECHNIQUE\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        # Layer 1\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 64, kernel_size=7, padding=3, stride=1),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Layer 2\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=4, padding=1, stride=2),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Layer 3\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=4, padding=1, stride=2),\n",
    "            nn.InstanceNorm2d(256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Layers 4-9: Residual blocks\n",
    "        self.residual_blocks = nn.Sequential(\n",
    "            *[ResidualBlock(256) for _ in range(6)]\n",
    "        )\n",
    "        \n",
    "        # Layer 10: Deconv\n",
    "        self.layer10 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Layer 11: Deconv\n",
    "        self.layer11 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Layer 12: Output layer\n",
    "        self.layer12 = nn.Sequential(\n",
    "            nn.Conv2d(64, 3, kernel_size=7, padding=3, stride=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, disaster_label):\n",
    "        # Concatenate the input image with the disaster label\n",
    "        disaster_label = disaster_label.view(disaster_label.size(0), -1, 1, 1)\n",
    "        disaster_label = disaster_label.repeat(1, 1, x.size(2), x.size(3))\n",
    "        x = torch.cat([x, disaster_label], dim=1)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.residual_blocks(x)\n",
    "        x = self.layer10(x)\n",
    "        x = self.layer11(x)\n",
    "        x = self.layer12(x)\n",
    "        \n",
    "        return x \n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num_disaster_types=5): ## CHANGE FOR DIFFERENT LABELING TECHNIQUE\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        # Layer 1\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Layer 2\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Layer 3\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Layer 4\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Layer 5a - Source prediction (real/fake)\n",
    "        self.source_layer = nn.Sequential(\n",
    "            nn.Conv2d(512, 1, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "        \n",
    "        # Layer 5b - Disaster type classification\n",
    "        self.classification_layer = nn.Sequential(\n",
    "            nn.Conv2d(512, num_disaster_types, kernel_size=4)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        features = self.layer4(x)\n",
    "        \n",
    "        # Source prediction\n",
    "        source_pred = self.source_layer(features)\n",
    "        \n",
    "        # Disaster type classification\n",
    "        class_pred = self.classification_layer(features)\n",
    "        class_pred = class_pred.view(class_pred.size(0), -1)\n",
    "        \n",
    "        return source_pred, class_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "783fbc35-2160-4aae-a1a3-3b12ff53c1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    df = pd.read_csv(args.csv_file)\n",
    "\n",
    "    dataset = DisasterDataset(df, args.img_dir)\n",
    "    dataloader = DataLoader(dataset,\n",
    "                            batch_size=args.batch_size,\n",
    "                            shuffle=True,\n",
    "                            num_workers=4)\n",
    "\n",
    "    generator = Generator().to(device)\n",
    "    discriminator = Discriminator(num_disaster_types=dataset.num_disaster_types).to(device)\n",
    "\n",
    "    g_optimizer = optim.Adam(generator.parameters(), lr=args.lr, betas=(0.5, 0.999))\n",
    "    d_optimizer = optim.Adam(discriminator.parameters(), lr=args.lr, betas=(0.5, 0.999))\n",
    "\n",
    "    gan_loss = GANLoss().to(device)\n",
    "    cls_loss = nn.CrossEntropyLoss()\n",
    "    rec_loss = nn.L1Loss()\n",
    "\n",
    "    # taken from Riu et al.\n",
    "    lambda_cls = 1\n",
    "    lambda_rec = 10\n",
    "\n",
    "    # Resume from latest checkpoint if it exists\n",
    "    checkpoint_path = 'checkpoints/latest.pth'\n",
    "    start_epoch = 0\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        print(f\"Resuming from {checkpoint_path}...\")\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        generator.load_state_dict(checkpoint['generator_state_dict'])\n",
    "        discriminator.load_state_dict(checkpoint['discriminator_state_dict'])\n",
    "        g_optimizer.load_state_dict(checkpoint['g_optimizer_state_dict'])\n",
    "        d_optimizer.load_state_dict(checkpoint['d_optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        print(f\"Resumed from epoch {start_epoch}\")\n",
    "\n",
    "    # Train until args.epochs\n",
    "    for epoch in range(start_epoch, args.epochs):\n",
    "        progress_bar = tqdm(dataloader, desc=f'Epoch {epoch+1}/{args.epochs}')\n",
    "        for batch in progress_bar:\n",
    "            real_images     = batch['post_image'].to(device)\n",
    "            pre_images      = batch['pre_image'].to(device)\n",
    "            disaster_onehot = batch['disaster_type'].to(device)\n",
    "            disaster_idx    = batch['disaster_idx'].to(device)\n",
    "\n",
    "            # === Train Discriminator ===\n",
    "            d_optimizer.zero_grad()\n",
    "            real_src_pred, real_cls_pred = discriminator(real_images)\n",
    "            d_real_src_loss = gan_loss(real_src_pred, True)\n",
    "            d_real_cls_loss = cls_loss(real_cls_pred, disaster_idx)\n",
    "\n",
    "            fake_images = generator(pre_images, disaster_onehot)\n",
    "            fake_src_pred, _ = discriminator(fake_images.detach())\n",
    "            d_fake_src_loss = gan_loss(fake_src_pred, False)\n",
    "\n",
    "            d_loss = -(-d_real_src_loss - d_fake_src_loss) + lambda_cls * d_real_cls_loss\n",
    "            d_loss.backward()\n",
    "            d_optimizer.step()\n",
    "\n",
    "            # === Train Generator ===\n",
    "            g_optimizer.zero_grad()\n",
    "            fake_src_pred, fake_cls_pred = discriminator(fake_images)\n",
    "            g_adv_loss = gan_loss(fake_src_pred, True)\n",
    "            g_cls_loss = cls_loss(fake_cls_pred, disaster_idx)\n",
    "\n",
    "            rec_images = generator(fake_images, disaster_onehot)\n",
    "            g_rec_loss = rec_loss(rec_images, real_images)\n",
    "\n",
    "            g_loss = g_adv_loss + lambda_cls * g_cls_loss + lambda_rec * g_rec_loss\n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "\n",
    "            progress_bar.set_postfix({\n",
    "                'D Loss': f'{d_loss.item():.4f}',\n",
    "                'G Loss': f'{g_loss.item():.4f}',\n",
    "                'Rec Loss': f'{g_rec_loss.item():.4f}'\n",
    "            })\n",
    "\n",
    "        # save after every epoch\n",
    "        os.makedirs('checkpoints', exist_ok=True)\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'generator_state_dict': generator.state_dict(),\n",
    "            'discriminator_state_dict': discriminator.state_dict(),\n",
    "            'g_optimizer_state_dict': g_optimizer.state_dict(),\n",
    "            'd_optimizer_state_dict': d_optimizer.state_dict(),\n",
    "        }, checkpoint_path)\n",
    "        print(f\"Checkpoint saved at epoch {epoch+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9fa47b9-fdfd-40c0-9a8d-3f675ecbb447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from checkpoints/latest.pth...\n",
      "Resumed from epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:   0%|                                                                                                                                                                         | 0/88 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 181.44 MiB is free. Including non-PyTorch memory, this process has 15.59 GiB memory in use. Of the allocated memory 14.20 GiB is allocated by PyTorch, and 1.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m args = SimpleNamespace(\n\u001b[32m      2\u001b[39m         csv_file=\u001b[33m'\u001b[39m\u001b[33m./hold_metadata.csv\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      3\u001b[39m         img_dir=\u001b[33m'\u001b[39m\u001b[33m./tier1/images/\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m      6\u001b[39m         lr=\u001b[32m0.0002\u001b[39m,\n\u001b[32m      7\u001b[39m     )\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m train(args)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 54\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(args)\u001b[39m\n\u001b[32m     51\u001b[39m d_real_src_loss = gan_loss(real_src_pred, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     52\u001b[39m d_real_cls_loss = cls_loss(real_cls_pred, disaster_idx)\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m fake_images = generator(pre_images, disaster_onehot)\n\u001b[32m     55\u001b[39m fake_src_pred, _ = discriminator(fake_images.detach())\n\u001b[32m     56\u001b[39m d_fake_src_loss = gan_loss(fake_src_pred, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ext3/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ext3/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 71\u001b[39m, in \u001b[36mGenerator.forward\u001b[39m\u001b[34m(self, x, disaster_label)\u001b[39m\n\u001b[32m     68\u001b[39m disaster_label = disaster_label.repeat(\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, x.size(\u001b[32m2\u001b[39m), x.size(\u001b[32m3\u001b[39m))\n\u001b[32m     69\u001b[39m x = torch.cat([x, disaster_label], dim=\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m x = \u001b[38;5;28mself\u001b[39m.layer1(x)\n\u001b[32m     72\u001b[39m x = \u001b[38;5;28mself\u001b[39m.layer2(x)\n\u001b[32m     73\u001b[39m x = \u001b[38;5;28mself\u001b[39m.layer3(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ext3/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ext3/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ext3/miniconda3/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = module(\u001b[38;5;28minput\u001b[39m)\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ext3/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ext3/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ext3/miniconda3/lib/python3.12/site-packages/torch/nn/modules/instancenorm.py:124\u001b[39m, in \u001b[36m_InstanceNorm.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m.dim() == \u001b[38;5;28mself\u001b[39m._get_no_batch_dim():\n\u001b[32m    122\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._handle_no_batch_input(\u001b[38;5;28minput\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._apply_instance_norm(\u001b[38;5;28minput\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ext3/miniconda3/lib/python3.12/site-packages/torch/nn/modules/instancenorm.py:47\u001b[39m, in \u001b[36m_InstanceNorm._apply_instance_norm\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m_apply_instance_norm\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.instance_norm(\n\u001b[32m     48\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m     49\u001b[39m         \u001b[38;5;28mself\u001b[39m.running_mean,\n\u001b[32m     50\u001b[39m         \u001b[38;5;28mself\u001b[39m.running_var,\n\u001b[32m     51\u001b[39m         \u001b[38;5;28mself\u001b[39m.weight,\n\u001b[32m     52\u001b[39m         \u001b[38;5;28mself\u001b[39m.bias,\n\u001b[32m     53\u001b[39m         \u001b[38;5;28mself\u001b[39m.training \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.track_running_stats,\n\u001b[32m     54\u001b[39m         \u001b[38;5;28mself\u001b[39m.momentum \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.momentum \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0.0\u001b[39m,\n\u001b[32m     55\u001b[39m         \u001b[38;5;28mself\u001b[39m.eps,\n\u001b[32m     56\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ext3/miniconda3/lib/python3.12/site-packages/torch/nn/functional.py:2876\u001b[39m, in \u001b[36minstance_norm\u001b[39m\u001b[34m(input, running_mean, running_var, weight, bias, use_input_stats, momentum, eps)\u001b[39m\n\u001b[32m   2874\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_input_stats:\n\u001b[32m   2875\u001b[39m     _verify_spatial_size(\u001b[38;5;28minput\u001b[39m.size())\n\u001b[32m-> \u001b[39m\u001b[32m2876\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m torch.instance_norm(\n\u001b[32m   2877\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   2878\u001b[39m     weight,\n\u001b[32m   2879\u001b[39m     bias,\n\u001b[32m   2880\u001b[39m     running_mean,\n\u001b[32m   2881\u001b[39m     running_var,\n\u001b[32m   2882\u001b[39m     use_input_stats,\n\u001b[32m   2883\u001b[39m     momentum,\n\u001b[32m   2884\u001b[39m     eps,\n\u001b[32m   2885\u001b[39m     torch.backends.cudnn.enabled,\n\u001b[32m   2886\u001b[39m )\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 181.44 MiB is free. Including non-PyTorch memory, this process has 15.59 GiB memory in use. Of the allocated memory 14.20 GiB is allocated by PyTorch, and 1.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "args = SimpleNamespace(\n",
    "        csv_file='./hold_metadata.csv',\n",
    "        img_dir='./tier1/images/',\n",
    "        epochs=5,\n",
    "        batch_size=32,\n",
    "        lr=0.0002,\n",
    "    )\n",
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b51e8ab0-7014-4416-86b6-e4cfe6195f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "def delete_latest_checkpoint(checkpoint_dir='checkpoints'):\n",
    "    # Get list of all checkpoint files sorted by modified time\n",
    "    checkpoint_files = glob.glob(os.path.join(checkpoint_dir, '*.pth'))\n",
    "    if not checkpoint_files:\n",
    "        print(\"No checkpoints found.\")\n",
    "        return\n",
    "\n",
    "    latest_checkpoint = max(checkpoint_files, key=os.path.getmtime)\n",
    "    os.remove(latest_checkpoint)\n",
    "    print(f\"Deleted latest checkpoint: {latest_checkpoint}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb5cbc3b-2d9c-4db0-8fd1-d6a98352184a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted latest checkpoint: checkpoints/latest.pth\n"
     ]
    }
   ],
   "source": [
    "delete_latest_checkpoint('checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c929f51-2d7a-41bc-9235-91d98c9fb92c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Custom Env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
